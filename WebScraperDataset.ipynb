{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmWYFg1rvnrFG2Bn9BiMYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atefeh62/Atefeh62/blob/main/WebScraperDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here I go through amazon webshop, and scrape data from the website, and save it as a csv file :"
      ],
      "metadata": {
        "id": "C3LG6mnUiWAn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "B5zpdZ_RiAVv"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Website and pull in data\n",
        "\n",
        "URL = 'https://www.amazon.com/dp/B07FWCH9MQ/ref=sspa_dk_detail_6?psc=1&pd_rd_i=B07FWCH9MQ&pd_rd_w=ixKXg&content-id=amzn1.sym.eb7c1ac5-7c51-4df5-ba34-ca810f1f119a&pf_rd_p=eb7c1ac5-7c51-4df5-ba34-ca810f1f119a&pf_rd_r=50026MZXW8KJEVRRC7A0&pd_rd_wg=fiUG2&pd_rd_r=08e68089-9b34-4b05-a9c1-9008aedc679c&s=apparel&sp_csd=d2lkZ2V0TmFtZT1zcF9kZXRhaWw'\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "page = requests.get(URL, headers=headers)\n",
        "\n",
        "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
        "\n",
        "title = soup2.find(id='productTitle').get_text()\n",
        "\n",
        "price = soup2.find(id='corePriceDisplay_desktop_feature_div').get_text()\n",
        "\n",
        "\n",
        "print(title)\n",
        "print(price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH0gZfZMiRqq",
        "outputId": "aaf85c2c-d977-4b5c-c7fb-759ffe9fd9ef"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                    Womens I Like Coffee and Maybe 3 People T Shirt Funny Sarcastic Tee for Ladies\n",
            "                   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                    $12.99\n",
            "                   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                      $\n",
            "                     \n",
            "\n",
            "                      12\n",
            "                      \n",
            "                       .\n",
            "                      \n",
            "\n",
            "\n",
            "                      99\n",
            "                     \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up the data a little bit\n",
        "\n",
        "price = price.strip()[1:7]\n",
        "title = title.strip()\n",
        "\n",
        "print(title)\n",
        "print(price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KthpaIOtkf_f",
        "outputId": "13f738ab-511a-4a71-c67f-32e656438091"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Womens I Like Coffee and Maybe 3 People T Shirt Funny Sarcastic Tee for Ladies\n",
            "12.99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Timestamp for the output to track the time that data was collected\n",
        "\n",
        "import datetime\n",
        "\n",
        "today = datetime.date.today()\n",
        "\n",
        "print(today)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxtgQOiOlLW1",
        "outputId": "c2729fb4-9e71-4c9b-dc77-f67d94d03375"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV and write headers and data into the file\n",
        "\n",
        "import csv\n",
        "\n",
        "header = ['Title', 'Price', 'Date']\n",
        "data = [title, price, today]\n",
        "\n",
        "\n",
        "with open('WebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "hsVahRGploBw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"C:\\Users\\hasan\\WebScraperDataset.csv\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "yOBgqB4_mqsE",
        "outputId": "d9e78ee1-f8a8-42e2-c156-3765a7b355a8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-59-9466174c03dd>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-9466174c03dd>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    df = pd.read_csv(\"C:\\Users\\hasan\\WebScraperDataset.csv\")\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we are appending data to the csv\n",
        "\n",
        "with open('WebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "F3JZO1v9uBds"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here, I want to check the price every day so I will define a function to do all the previous steps and then by the time as second the function would work everyday:"
      ],
      "metadata": {
        "id": "sWqPp30qAUGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine all of the above code into one function for the purpose of automation:\n",
        "\n",
        "\n",
        "def check_price():\n",
        "    URL = 'https://www.amazon.com/dp/B07FWCH9MQ/ref=sspa_dk_detail_6?psc=1&pd_rd_i=B07FWCH9MQ&pd_rd_w=ixKXg&content-id=amzn1.sym.eb7c1ac5-7c51-4df5-ba34-ca810f1f119a&pf_rd_p=eb7c1ac5-7c51-4df5-ba34-ca810f1f119a&pf_rd_r=50026MZXW8KJEVRRC7A0&pd_rd_wg=fiUG2&pd_rd_r=08e68089-9b34-4b05-a9c1-9008aedc679c&s=apparel&sp_csd=d2lkZ2V0TmFtZT1zcF9kZXRhaWw'\n",
        "\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "    page = requests.get(URL, headers=headers)\n",
        "\n",
        "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
        "\n",
        "    title = soup2.find(id='productTitle').get_text()\n",
        "\n",
        "    price = soup2.find(id='corePriceDisplay_desktop_feature_div').get_text()\n",
        "\n",
        "    price = price.strip()[1:7]\n",
        "    title = title.strip()\n",
        "\n",
        "    import datetime\n",
        "\n",
        "    today = datetime.date.today()\n",
        "\n",
        "    import csv\n",
        "\n",
        "    header = ['Title', 'Price', 'Date']\n",
        "    data = [title, price, today]\n",
        "\n",
        "    with open('WebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(data)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4dgawS1h_GpZ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs check_price after a set time and inputs data into your CSV\n",
        "\n",
        "while(True):\n",
        "    check_price()\n",
        "    time.sleep(86400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "R1Z_W6lPAJQg",
        "outputId": "cbf570a5-59a5-4f71-af0e-80b852bb2ee4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-3b963dbed188>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcheck_price\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m86400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"C:\\Users\\hasan\\WebScraperDataset.csv\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "3y0-0hbzBxam"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}